##  **Анализ алгоритма: Сортировка обменом (пузырьком) (Bubble Sort)**

**Определение:**
Алгоритм сортировки пузырьком проходит по массиву, сравнивая каждую пару соседних элементов. Если текущий элемент больше следующего — они меняются местами. Таким образом, наибольшие элементы постепенно «всплывают» в конец массива, как пузырьки в воде, откуда и название алгоритма.

**Ход работы:**

1. Сравниваются первые два элемента. Если первый больше — выполняется обмен.
2. Затем сравниваются второй и третий, третий и четвёртый и т.д., пока не дойдут до конца массива.
3. После первого прохода самый большой элемент оказывается в конце.
4. Процесс повторяется для оставшихся элементов (без последнего), пока весь массив не станет отсортированным.

**Анализ:**

* Количество проходов по массиву — *(n - 1)*.
* На первом проходе выполняется *(n - 1)* сравнений, на втором — *(n - 2)*, и так далее.
* В сумме это даёт примерно *n(n - 1)/2* сравнений.
* Количество обменов зависит от изначального порядка: в худшем случае (обратная сортировка) обмен выполняется почти при каждом сравнении.

**Временная сложность:**

* Лучший случай (массив уже отсортирован): **O(n)** — достаточно одного прохода без обменов.
* Средний и худший случаи: **O(n²)**.

**Память:**

* Алгоритм выполняется «на месте» — **O(1)** дополнительной памяти.

**Преимущества:** простая реализация, нагляден для обучения.
**Недостатки:** медленный на больших данных, неэффективен по сравнению с другими методами.

---

##  **Анализ алгоритма: Сортировка вставками (Insertion Sort)**

**Определение:**
Алгоритм сортировки вставками напоминает процесс, как человек сортирует карты в руке. Он постепенно берёт по одной карте из колоды и вставляет её в нужное место среди уже упорядоченных карт.

**Ход работы:**

1. Считаем, что первый элемент уже отсортирован.
2. Берём следующий элемент и сравниваем его с элементами в отсортированной части массива.
3. Если текущий элемент меньше, элементы сдвигаются вправо, чтобы освободить место.
4. Вставляем текущий элемент в найденное место.
5. Повторяем для всех элементов.

**Анализ:**

* Каждый элемент, начиная со второго, может сравниваться с предыдущими до тех пор, пока не найдёт свою позицию.
* Количество сравнений и сдвигов при худшем расположении данных (в обратном порядке) составляет около *n(n - 1)/2*.
* При почти отсортированных данных работает гораздо быстрее.

**Временная сложность:**

* Худший случай: **O(n²)**
* Средний случай: **O(n²)**
* Лучший случай (массив уже отсортирован): **O(n)**

**Память:** **O(1)**

**Особенности:**
Эффективен на небольших массивах и почти отсортированных данных. Часто используется как часть гибридных алгоритмов (например, в TimSort).

---

##  **Анализ алгоритма: Сортировка слиянием (Merge Sort)**

**Определение:**
Сортировка слиянием — это рекурсивный алгоритм, основанный на принципе «разделяй и властвуй». Он делит массив на две части, сортирует каждую из них и затем объединяет (сливает) их в один отсортированный массив.

**Ход работы:**

1. Делим массив пополам до тех пор, пока не останутся отдельные элементы.
2. Начинаем слияние соседних элементов, сравнивая и объединяя их в отсортированном порядке.
3. Постепенно формируется отсортированный массив.

**Анализ:**

* Глубина рекурсии — *log₂(n)* уровней.
* На каждом уровне объединяются все элементы массива — это O(n) операций.
* Следовательно, общая сложность: *O(n log n)*.

**Временная сложность:**

* Худший, средний и лучший случаи: **O(n log n)**

**Память:**

* Требуется дополнительный массив для хранения результатов слияния: **O(n)**.

**Особенности:**
Стабильный и предсказуемый алгоритм, часто используется для сортировки больших объёмов данных. Работает одинаково независимо от начального состояния массива.

---

##  **Анализ алгоритма: Сортировка Шелла (Shell Sort)**

**Определение:**
Сортировка Шелла — это улучшенная версия сортировки вставками, в которой элементы сравниваются на определённом расстоянии (gap). Сначала расстояние большое, а затем постепенно уменьшается, пока не станет равным 1.

**Ход работы:**

1. Выбирается интервал (gap), например n/2.
2. Элементы, находящиеся на расстоянии gap, сортируются между собой методом вставки.
3. Gap уменьшается (обычно вдвое).
4. Повторяется процесс, пока gap = 1.

**Анализ:**

* Сравнения и обмены зависят от последовательности интервалов.
* На каждом уменьшении gap элементы всё ближе к своим позициям, и финальная вставка выполняется быстро.

**Временная сложность:**

* В среднем: **от O(n^(3/2)) до O(n log² n)**
* Худший случай: **O(n²)**
* Лучший случай: **O(n log n)**

**Память:** **O(1)**

**Особенности:**
Сортировка Шелла быстрее обычной сортировки вставками. Хороша для средних объёмов данных и часто используется в системах с ограниченной памятью.

---

##  **Анализ алгоритма: Быстрая сортировка (Quick Sort)**

**Определение:**
Быстрая сортировка (Quick Sort) также использует стратегию «разделяй и властвуй». Основная идея — выбрать опорный элемент (pivot), разделить массив на элементы меньше и больше опорного, а затем рекурсивно отсортировать обе части.

**Ход работы:**

1. Выбирается опорный элемент (например, середина массива).
2. Элементы меньше pivot помещаются слева, больше — справа.
3. Алгоритм рекурсивно вызывается для левой и правой частей.
4. После завершения всех вызовов массив оказывается отсортированным.

**Анализ:**

* При равномерном разбиении глубина рекурсии ~ *log₂(n)*.
* Каждое разбиение требует O(n) сравнений.
* Средняя сложность — *O(n log n)*.
* При неудачном выборе pivot (всегда минимальный или максимальный элемент) — до *O(n²)*.

**Временная сложность:**

* Средний случай: **O(n log n)**
* Худший случай: **O(n²)**
* Лучший случай: **O(n log n)**

**Память:**

* Зависит от рекурсии: **O(log n)**

**Особенности:**
Один из самых быстрых практических алгоритмов. Используется в стандартных библиотеках языков программирования (например, C++ и Java).

---

##  **Анализ алгоритма: Пирамидальная сортировка (Heap Sort)**

**Определение:**
Пирамидальная сортировка основывается на структуре данных под названием «бинарная куча» (heap). Сначала из массива создаётся максимальная куча, затем извлекается максимальный элемент и помещается в конец массива, после чего структура перестраивается.

**Ход работы:**

1. Построить кучу из всех элементов.
2. Поместить корень (наибольший элемент) в конец массива.
3. Уменьшить размер кучи на 1 и перестроить её.
4. Повторять, пока не останется один элемент.

**Анализ:**

* Построение кучи выполняется за O(n).
* Каждое извлечение максимума требует O(log n).
* Так как извлекается n элементов, общая сложность O(n log n).

**Временная сложность:**

* Все случаи: **O(n log n)**

**Память:** **O(1)**

**Особенности:**
Стабильность не гарантируется, но алгоритм надёжен и эффективен. Подходит, когда нужно сортировать на месте без использования дополнительной памяти.

---

##  **Анализ алгоритма: Последовательный (линейный) поиск (Linear Search)**

**Определение:**
Линейный поиск проверяет элементы массива один за другим, пока не найдёт нужный или не дойдёт до конца.

**Ход работы:**

1. Сравниваем искомое значение с первым элементом.
2. Если совпадает — поиск завершён.
3. Если нет — переходим к следующему.
4. Повторяем до конца массива.

**Анализ:**

* Проверяется до n элементов.
* Эффективен только для небольших или неотсортированных массивов.

**Временная сложность:**

* Лучший случай: **O(1)** (если элемент первый).
* Средний: **O(n/2)**
* Худший: **O(n)**

**Память:** **O(1)**

---

##  **Анализ алгоритма: Бинарный поиск (Binary Search)**

**Определение:**
Бинарный поиск работает только с отсортированными данными. Он сравнивает искомое значение с серединой массива и исключает половину элементов из рассмотрения.

**Ход работы:**

1. Определяем середину диапазона.
2. Если элемент равен середине — поиск завершён.
3. Если меньше — ищем в левой половине, если больше — в правой.
4. Повторяем до нахождения элемента или пока диапазон не станет пустым.

**Анализ:**

* После каждого шага остаётся половина элементов.
* Количество шагов ≈ *log₂(n)*.

**Временная сложность:**

* Все случаи: **O(log n)**

**Память:**

* При итеративной реализации: **O(1)**
* При рекурсивной: **O(log n)**

---

##  **Анализ алгоритма: Интерполирующий поиск (Interpolation Search)**

**Определение:**
Интерполирующий поиск — усовершенствованная версия бинарного поиска, которая оценивает вероятное положение искомого элемента, исходя из его значения.

**Ход работы:**

1. Используется формула пропорции, чтобы предсказать позицию элемента.
2. Если элемент меньше — ищем левее, если больше — правее.
3. Повторяем до нахождения или пока диапазон не сократится до нуля.

**Анализ:**

* Эффективен при равномерном распределении данных.
* В среднем выполняет около *log log n* сравнений.
* При неравномерных данных — до *O(n)*.

**Временная сложность:**

* Средний случай: **O(log log n)**
* Худший случай: **O(n)**

**Память:** **O(1)**

---

##  **Анализ алгоритма: Поиск по Фибоначчи (Fibonacci Search)**

**Определение:**
Этот метод похож на бинарный поиск, но делит диапазон не пополам, а в соответствии с числами Фибоначчи. Это делает его удобным для систем, где деление на два неэффективно (например, в некоторых старых архитектурах).

**Ход работы:**

1. Вычисляется наибольшее число Фибоначчи, меньшее длины массива.
2. Определяется индекс для проверки по этому числу.
3. После каждого шага диапазон сокращается в зависимости от последовательности Фибоначчи.
4. Процесс продолжается, пока элемент не найден.

**Анализ:**

* Количество шагов пропорционально *logφ(n)* (φ — золотое сечение).
* Эффективность аналогична бинарному поиску.

**Временная сложность:** **O(log n)**
**Память:** **O(1)**

**Особенности:**
Требует только арифметических операций и прост в реализации. В некоторых случаях устойчивее к колебаниям в распределении данных, чем бинарный поиск.
